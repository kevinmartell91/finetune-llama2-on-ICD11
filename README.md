# Finetune LLaMA-2 on ICD-11 data

## Goal 
This project is focused on achieving high-quality results with different open source Large Language Models (LLMs), using Lamini SDK.

## Project description

To achieve the goal, the project is broken down into demoable applications or milestones. Each item is a subproject that contains its own README.md file with description, installation instructions, usage, and examples.

## Milestone (demoable applications)

- [ ] Chat app - calls an LLM from:
    - [X] Python client
    - [ ] React client
    - [ ] Slack client
- [ ] Retrieval Augmented generation (RAG) - combine information retrieval with text generation to improve language models
- [ ] Instruction Fine Tuning (IFT) - train the model using question-answer pairs
- [ ] Evaluations - evaluate the quality of the LLM with RLHF-alike techniques (DPO) and RLAIF
- [ ] Classify - classify data using an LLM, e.g. to filter out low-quality training data

## Installation instructions
To achieve reproducible and clean development environments, this project relies on Docker. Each demoable application has its own installation instructions in its README file.

### Installed extensions to have better and smoother Docker experience
- Docker (makes it easy to create, manage, and debug containerized applications)
- Dev containers (allows us to attach to running container)

## Usage and examples
Coming soon in this document.