# Playground Clients

It is very important to automate our interaction with LLMs. Therefore, creating our own tool is a good alternative to:
1. Optimize for a higher number of experiments in less time
2. Create virtuous workflows: allow our teammates to use LLMs via one of these clients and get feedback. (then repeat points 1 and 2 multiple times)

## How to run the clients
There are two ways of running the clients:
1. Using Docker.
2. Following the Markdown file that has the name of the client, which has the instructions to run without Docker.

Both instructions are Markdown files of each client.

## Clients
In this directory, there are some clients used to interact with our LLM models programmatically.
1. [Python client](https://github.com/lamini-ai/lamini-sdk/blob/main/01_playground/python_client/python_client.md) : this is simple python client to call an LLM.




